import dumbgen;
import state;

/* We need to figure out what cell is what.

In a function body, cells fit in exactly ONE leaf node of this tree of categories:

 - subcells of some other cell
   - constant offset subcells
   - computed offset subcells -- location depends on another cell
 - not a subcell
   - static cells -- these can be statically located
     - outer cells -- pre-existing, locations taken as given
    //  - globals (these do not exist yet)
        - outer func paramlist & return cell
     - paramlist cells -- part of a func paramlist in GrApply
     - free cells -- temporaries, variables, we can locate them anywhere in the stack frame.
   - deref cells -- formed by dereferencing a pointer

Some more definitions:
 - A cell is "statically locatable" if it is a static cell or a constant offset subcells
   of a statically locatable cell.
 - "Statlocat" is an abbrevation for "statically locatable."
 - A cell is "derefalike" if it is a deref cell or a subcell of a derefalike cell.

We should find that some restrictions are upheld:

 - subcells are always subcells of exactly one cell, declared in exactly one node.  hell,
   every cell is sort of defined by exactly one node.
 - computed offset subcells' location cells must be statlocat.
 - GrApply return cells must be statlocat (for now).
 - paramlist cells can only be part of one func paramlist.
*/

/* What we want to do:

  At a minimum, we want to know whether a cell is a paramlist cell, and what paramlist
  it's part of.
*/

struct subcell_disp {
  subcell_opnum gr_num;
  partof cell_num;
  offset gr_offset;
}

enum cell_const_disp {
  NoConstDisp void;
  HasConstValue gr_const;
  NotConst void;
}

struct cell_disp {
  // If the cell's part of a function param list, tells what paramlist it's part of.
  paramlist opt[sq_num];
  // If the cell's part of a primop param list, tells what paramlist it's part of.
  prim_paramlist opt[sq_num];
  // If the cell's a funcell of a GrApply, tells what paramlist it's applying.  Or tells
  // what paramlist it used to apply, if the function got inlined.
  funcell opt[gr_num];
  // If the cell's value is used, outside of a funcell.
  value_used bool;
  // If the cell's a subcell of another, tells what it's a subcell of.
  subcell opt[subcell_disp];
  // If the cell has a constant value.  (Must be a static cell.)
  const_value cell_const_disp;

  // Which cells are alive at the same time as this one (except this one).
  // This can have duplicates, but it won't have many.
  conflicting array[cell_num];

  // Which cells are subcells of this one.
  subcelled array[cell_num];
}

struct basic_analyze_state {
  // This means we've analyzed gns [0, gns_analyzed).  But we haven't analyzed further gns.
  gns_analyzed size;
  paramlists array[sq_num];
  celldisp array[cell_disp];
}

func basic_analyze_fn_body(cs *checkstate, g *graphed_fn_body, bas_out *basic_analyze_state) void {
  bas basic_analyze_state = {0, mk_array@[sq_num](), mk_array@[cell_disp]()};

  help_basic_analyze(cs, &bas, &g->graph.gr);

  // TODO: Check mutual exclusivity of celldisps -- cells can't be certain combinations of things.

  *bas_out = bas;
}

func help_basic_analyze_xnode(cs *checkstate, bas *basic_analyze_state, gr *frame_graph,
                              sn sq_num, gn gr_num, xn *gr_xnode) void {
  switch &xn->op {
  case &GrApply(a gr_apply):
    push(&bas->paramlists, sn);
    funcell_cd *cell_disp = ref(&bas->celldisp, a.funcell.x);
    if case &Has(other_gn gr_num) = &funcell_cd->funcell {
      ice(_u8("two-timing funcell "), a.funcell.x, _u8(" for "), other_gn.x, _u8(" and "), gn.x);
    } else {
      funcell_cd->funcell = Has(gn);
    }
    nparams size = count(&a.params);
    for j size = 0; j < nparams; j = j + 1 {
      mark_cell_paramlist(bas, get(&a.params, j), sn);
    }
    mark_cell_not_const(bas, a.retcell);
  case &GrPrimApply(a gr_prim_apply):
    nparams size = count(&a.params);
    for j size = 0; j < nparams; j = j + 1 {
      mark_cell_prim_paramlist(bas, get(&a.params, j), sn);
    }
    mark_cell_not_const(bas, a.retcell);
  case &GrMemCopy(a gr_memcopy):
    mark_cell_value_used(bas, a.src);
    mark_cell_not_const(bas, a.dest);
  case &GrWriteConst(a gr_writeconst):
    if case LocationStatic = ref(&gr->cells, a.dest.x)->location {
      disp *cell_const_disp = &ref(&bas->celldisp, a.dest.x)->const_value;
      switch disp {
      case &NoConstDisp:
        *disp = HasConstValue(a.value);
      case &HasConstValue(gc gr_const):
        *disp = NotConst;
      case &NotConst:
        void;
      }
    }
  case &GrAddressof(a gr_addressof):
    mark_cell_value_used(bas, a.addressee);
    // If this is the address of a static cell, the value is actually const.  But we
    // ignore that possibility.
    mark_cell_not_const(bas, a.dest);
    mark_cell_not_const(bas, a.addressee);
  case &GrSubcell(a gr_subcell):
    set(&ref(&bas->celldisp, a.name.x)->subcell, {gn, a.partof, a.offset});
    push(&ref(&bas->celldisp, a.partof.x)->subcelled, a.name);
    check(ref(&gr->cells, a.name.x)->location == LocationVirtual);
    mark_cell_not_const(bas, a.partof);
    mark_cell_value_used(bas, a.name);
    mark_cell_value_used(bas, a.partof);
  default:
    void;
  }
}

func help_basic_analyze(cs *checkstate, bas *basic_analyze_state, gr *frame_graph) void {
  n_ops size = count(&gr->ops);
  cellcount size = count(&gr->cells);
  grow(&bas->celldisp, cellcount - count(&bas->celldisp),
       {None, None, None, false, None, NoConstDisp, mk_array@[cell_num](), mk_array@[cell_num]()});

  for i size = bas->gns_analyzed; i < n_ops; i = i + 1 {
    if case &QOp(qn gr_qnode) = ref(&gr->ops, i) {
      switch &qn.op {
      case &GrBranch(a gr_branch):
        mark_cell_value_used(bas, a.src);
      case &GrSequence(a gr_sequence):
        xn *gr_xnode = ref_xnode(gr, a.first);
        help_basic_analyze_xnode(cs, bas, gr, ~(@[gr_num]~i), a.first, xn);
      default:
        void;
      }
    }
  }
  bas->gns_analyzed = n_ops;
}

func mark_cell_value_used(bas *basic_analyze_state, c cell_num) void {
  p *cell_disp = ref(&bas->celldisp, c.x);
  p->value_used = true;
}

// Also marks value_used.
func mark_cell_paramlist(bas *basic_analyze_state, c cell_num, apply_sqnum sq_num) void {
  p *cell_disp = ref(&bas->celldisp, c.x);
  set(&p->paramlist, apply_sqnum);
  p->value_used = true;
}

// Also marks value_used.
func mark_cell_prim_paramlist(bas *basic_analyze_state, c cell_num, apply_sqnum sq_num) void {
  p *cell_disp = ref(&bas->celldisp, c.x);
  set(&p->prim_paramlist, apply_sqnum);
  p->value_used = true;
}

func mark_cell_not_const(bas *basic_analyze_state, c cell_num) void {
  ref(&bas->celldisp, c.x)->const_value = NotConst;
}

func basic_and_inline(cs *checkstate, g *graphed_fn_body) np {
  switch &g->inline_state {
  case &NotComputed:
    g->inline_state = BeganComputing;
    bas basic_analyze_state;
    basic_analyze_fn_body(cs, g, &bas);

    if case Unprinted(pm) = help_basic_inline_inlinables(cs, &bas, g) {
      g->inline_state = FailedComputation;
      return Unprinted(pm);
    }
    g->inline_state = Computed(bas);
    return NoFail;
  case &BeganComputing:
    g->inline_state = FailedComputation;
    return ERR(_u8("Recursively inlining function "), lookup(cs->im, g->graph.gr.informal_name));
  case &FailedComputation:
    return ERR(_u8("basic_inline_inlinables already failed for "),
               lookup(cs->im, g->graph.gr.informal_name));
  case &Computed(x basic_analyze_state):
    return NoFail;
  }
}

func help_basic_inline_inlinables(cs *checkstate, bas *basic_analyze_state, g *graphed_fn_body) np {
  gr *frame_graph = &g->graph.gr;
  // nparamlists is _not_ constant.
  nparamlists size = count(&bas->paramlists);
  new_paramlists array[sq_num];
  for i size = 0; i < nparamlists; i = i + 1 {
    sn sq_num = get(&bas->paramlists, i);
    gsq gr_sequence = *ref_grsequence(gr, sn);
    // (We avoid retaining references into arrays that we'll modify -- so we copy out the gr_apply.)
    a gr_apply = *as_gr_apply(ref_node(gr, gsq.first));
    // TODO: Remove vestigial funcell (if nothing ever reads it) after inlining.  (Somehow.)
    if case Has(fnid fn_body_id) = is_const_funcell(cs, bas, a.funcell) {
      ent *fn_body_entry = ref_fn_body(cs, fnid);
      switch &ent->u {
      case &GraphedFnBody(eg graphed_fn_body):
        switch eg.inline {
        case InlineMust:
          #basic_and_inline(cs, &eg);
          nparams size = count(&a.params);
          check(count(&eg.argcells) == nparams);
          // Okay, we're inlining.
          nec size = count(&eg.graph.gr.cells);
          cell_mapping array[cell_num];
          reserve(&cell_mapping, nec);
          for j size = 0; j < nec; j = j + 1 {
            mapped cell_num;
            if case Has(k size) = find(&eg.argcells, ~j) {
              // TODO: Assert that the cell types in g and eg are equal?  The sizes?
              mapped = get(&a.params, k);
            } else if eg.graph.cell == ~j {
              // TODO: Assert that the cell types in g and eg are equal?  The sizes?
              mapped = a.retcell;
            } else {
              egi *cell_info = ref(&eg.graph.gr.cells, j);
              mapped = add_cell(gr, {egi->location, egi->type, egi->props});
            }
            push(&cell_mapping, mapped);
          }

          op_addend size = count(&gr->ops);

          neo size = count(&eg.graph.gr.ops);
          for j size = 0; j < neo; j = j + 1 {
            push(&gr->ops, adjust_op_for_inline(op_addend, &cell_mapping, get(&eg.graph.gr.ops, j)));
          }

          entry_op_adjusted sq_num = {~(eg.graph.ee.entry.x.x + op_addend)};
          exit_op_adjusted sq_num = {~(eg.graph.ee.exit.x.x + op_addend)};

          // Now we overwrite the apply op.  A GrApply always needs the return cell to
          // be live before it's called.  So we add GrAssertLive to verify that's the
          // case.
          funcell_inactive_op gr_num =
            untracked_addx(gr, @[gr_xop]GrActiveXop({Deactivate(a.funcell), Nothing}));
          funcell_dead_op gr_num = untracked_addx(gr, @[gr_xop]GrDead({a.funcell}));

          post_seqer sq_num;
          switch a.act {
          case StandardApply:
            post_seqer = gsq.second;
          case TwoExtraOps(ops gr_active_xop):
            post_seqer = seqqgar(gr,
                                 {untracked_addx(gr, @[gr_xop]GrActiveXop(ops)),
                                  gsq.second});
          }

          seqer sq_num =
            seqqgar(gr, {funcell_inactive_op,
                         seqqgar(gr, {funcell_dead_op,
                                      seqqgar(gr, {untracked_addx(gr, @[gr_xop]GrAssertLive({a.retcell})),
                                                   entry_op_adjusted})})});

          jmp_qnop_node(gr, exit_op_adjusted, post_seqer, JmpForward);

          // Note that our GrActiveXop(a.act) above makes our active tracking correct
          // but it also describes another "hole" in the exception safety -- one that
          // still exists if we don't inline functions (in particular, constructors)
          // too.


          // TODO: It'd be nice if we could undo the mark_cell_not_const of a.retcell
          // (that happened when we processed GrApply in help_basic_analyze before).

          // We set it to QNop first, then use jmp_qnop_node, to reuse
          // indegree-updating logic.  seqer gets its indegree incremented from 0 to
          // 1.
          *ref(&gr->ops, sn.x.x) = QOp({GrQNop, @[gr_qnode_indegree]{0}, garbage_seg()});
          jmp_qnop_node(gr, sn, seqer, JmpForward);

          // And since there's no apply op, we update the arg/funcell cell_disps.
          // Actually, we don't update the funcell disp, so that we don't allocate/write its cell needlessly.
          // unSet(&ref(&bas->celldisp, a.funcell.x)->funcell);
          for j size = 0; j < nparams; j = j + 1 {
            unSet(&ref(&bas->celldisp, get(&a.params, j).x)->paramlist);
          }

          help_basic_analyze(cs, bas, gr);
          nparamlists = count(&bas->paramlists);
        case InlineYawn:
          push(&new_paramlists, sn);
        }
      default:
        push(&new_paramlists, sn);
      }
    } else {
      push(&new_paramlists, sn);
    }
  }
  swap(&bas->paramlists, &new_paramlists);
  return NoFail;
}

func adjust_active_op_for_inline(cm *array[cell_num], op gr_active_op) gr_active_op {
  switch op {
  case Nothing:
    return Nothing;
  case Activate(c cell_num):
    return Activate(get(cm, c.x));
  case Deactivate(c cell_num):
    return Deactivate(get(cm, c.x));
  }
}

inline func adjust(op_addend size, gn gr_num) gr_num {
  return ~(gn.x + op_addend);
}

inline func adjust(op_addend size, sn sq_num) sq_num {
  return ~ adjust(op_addend, sn.x);
}

func adjust(op_addend size, disposition gr_branch_disposition) gr_branch_disposition {
  switch disposition {
  case ForwardBranch(sn sq_num):
    return ForwardBranch(adjust(op_addend, sn));
  case LoopingBranch:
    return LoopingBranch;
  case ExceptionalBranch:
    return ExceptionalBranch;
  }
}

func adjust_disposition_for_inline(op_addend size, disposition gr_jmp_disposition) gr_jmp_disposition {
  switch disposition {
  case JmpForward:
    return JmpForward;
  case ExitNormalcy(ex gr_jmp_exit_normalcy):
    return ExitNormalcy({adjust(op_addend, ex.subsequent_normalcy)});
  case ReenterNormalcy:
    return ReenterNormalcy;
  }
}

func adjust_xop_for_inline(op_addend size, cm *array[cell_num], xop *gr_xop) gr_xop {
  switch xop {
  case &GrApply(a gr_apply):
    act gr_apply_active_change;
    switch a.act {
    case TwoExtraOps(ops gr_active_xop):
      act = TwoExtraOps({adjust_active_op_for_inline(cm, ops.op1), adjust_active_op_for_inline(cm, ops.op2)});
    case StandardApply:
      act = StandardApply;
    }

    return GrApply({get(cm, a.funcell.x), help_adjust_params(cm, &a.params), get(cm, a.retcell.x), act});
  case &GrPrimApply(a gr_prim_apply):
    return GrPrimApply({a.primop, help_adjust_params(cm, &a.params), get(cm, a.retcell.x)});
  case &GrMemCopy(a gr_memcopy):
    return GrMemCopy({get(cm, a.dest.x), get(cm, a.src.x)});
  case &GrWriteConst(a gr_writeconst):
    return GrWriteConst({get(cm, a.dest.x), a.value});
  case &GrAddressof(a gr_addressof):
    return GrAddressof({get(cm, a.dest.x), get(cm, a.addressee.x)});
  case &GrDeref(a gr_deref):
    return GrDeref({get(cm, a.name.x), get(cm, a.pointer.x), help_adjust_offset(cm, &a.offset)});
  case &GrSubcell(a gr_subcell):
    return GrSubcell({get(cm, a.name.x), get(cm, a.partof.x), help_adjust_offset(cm, &a.offset)});
  case &GrLive(a gr_live):
    return GrLive({get(cm, a.cell.x)});
  case &GrAssertLive(a gr_assert_live):
    return GrAssertLive({get(cm, a.cell.x)});
  case &GrDead(a gr_dead):
    return GrDead({get(cm, a.cell.x)});
  case &GrVirtualDead(a gr_virtual_dead):
    return GrVirtualDead({get(cm, a.cell.x)});
  case &GrActiveXop(a gr_active_xop):
    return GrActiveXop({adjust_active_op_for_inline(cm, a.op1), adjust_active_op_for_inline(cm, a.op2)});
  case &GrManyActiveXop(a gr_many_active_xop):
    adjusted array[gr_active_op];
    nops size = count(&a.ops);
    for i size = 0; i < nops; i = i + 1 {
      push(&adjusted, adjust_active_op_for_inline(cm, get(&a.ops, i)));
    }
    return GrManyActiveXop({freeze(&adjusted)});
  }
}

func adjust_op_for_inline(op_addend size, cm *array[cell_num], node gr_node) gr_node {
  switch node {
  case XOp(xn gr_xnode):
    return XOp({adjust_xop_for_inline(op_addend, cm, &xn.op)});
  case QOp(qn gr_qnode):
    switch &qn.op {
    case &GrBranch(a gr_branch):
      newcases array[gr_branch_pair];
      ncases size = count(&a.cases);
      for i size = 0; i < ncases; i = i + 1 {
        cas *gr_branch_pair = &a.cases[i];
        push(&newcases, {cas->value, {adjust(op_addend, cas->target.sn), cas->target.disposition}});
      }
      defaultcase opt[gr_branch_target];
      if case Has(def_target gr_branch_target) = a.default_case {
        defaultcase = Has({adjust(op_addend, def_target.sn), def_target.disposition});
      } else {
        defaultcase = None;
      }
      return QOp({GrBranch({get(cm, a.src.x), freeze(&newcases), defaultcase,
                            @[gr_branch_info]{adjust(op_addend, a.info.disposition)}}),
                  qn.indegree, garbage_seg()});
    case &GrSequence(a gr_sequence):
      return QOp({GrSequence({adjust(op_addend, a.first), adjust(op_addend, a.second)}),
                  qn.indegree, garbage_seg()});
    case &GrJmp(a gr_jmp):
      return QOp({GrJmp({adjust(op_addend, a.next), adjust_disposition_for_inline(op_addend, a.disposition)}),
                  qn.indegree, garbage_seg()});
    case &GrQNop:
      return QOp({GrQNop, qn.indegree, garbage_seg()});
    }
  }
}

func help_adjust_params(cm *array[cell_num], params *shray[cell_num]) shray[cell_num] {
  ret array[cell_num];
  n size = count(params);
  for i size = 0; i < n; i = i + 1 {
    push(&ret, get(cm, get(params, i).x));
  }
  return freeze(&ret);
}

func help_adjust_offset(cm *array[cell_num], off *gr_offset) gr_offset {
  switch off {
  case &OffsetConst(x gr_offset_const):
    return OffsetConst(x);
  case &OffsetComputed(p gr_offset_computed):
    return OffsetComputed({p.array_elem_size, get(cm, p.ix_cell.x)});
  }
}
