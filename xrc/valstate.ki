struct vt_state {
  supports array[vs_support];
  checksum vs_checksum;
}

struct vs_checksum {
  // These counts may go negative, because we start them from zero after a paramlist is set-up.  They just have to be consistent, they're a basic sanity-check.
  live_count i32;
  active_count i32;
}

func mk_vt_state() vt_state {
  return {mk_array@[vs_support](), @[vs_checksum]{0, 0}};
}

struct vs_support {
  supporter vs_supporter;
  supportee cell_num;
}

enum vs_supporter {
  // A pointer, it points at the supportee.
  PointerFrom cell_num;
  // Supportee is a field of the given cell.
  FieldOf cell_num;
  // A descoping element.  Not sure if cell_num actually gets used -- it is informative though.
  DescopingElement cell_num;
  // We've lost track of the cell's support.  TODO: Get rid of this.
  LostTrack void;
}

enum freshness {
  Stale void;
  // There's a change in the information formed by unification.
  Fresh void;
}

func `==`(x freshness, y freshness) bool {
  return enumnum(&x) == enumnum(&y);
}

// Returns whether "onto" changed.
func unify_vt_state(onto *opt[vt_state], from *vt_state) cr[freshness] {
  if case &Has(s vt_state) = onto {
    return unify_vt_state(&s, from);
  } else {
    *onto = Has(*from);
    return NoFail(Fresh);
  }
}

// Returns whether "onto" changed.
func unify_vt_state(onto *vt_state, from *vt_state) cr[freshness] {
  #unify_vs_checksum(&onto->checksum, &from->checksum);
  return unify_vs_support(onto, from);
}

func unify_vs_checksum(onto *vs_checksum, from *vs_checksum) np {
  if onto->live_count == from->live_count && onto->active_count == from->active_count {
    return NoFail;
  } else {
    return ERR(_u8("ICE? unify_vt_state active/live count mismatch"));
  }
}

// Well.  This sure seems like a bespoke thing that won't last.
struct vs_unify_half_pairage {
  // Does it have a descoping element?  (Whose cell_num must be the same ofc.)
  descoping bool;
  // Does it have FieldOf support?
  fieldof opt[cell_num];
  // What are our PointerFroms?
  inpointers array[cell_num];
  // Did we "lose track"?
  losttrack bool;
}

struct vs_unify_pairage {
  for_onto vs_unify_half_pairage;
  for_from vs_unify_half_pairage;
}

func unify_vs_support(onto *vt_state, from *vt_state) cr[freshness] {
  // Okay, how is this gonna work.
  // Essentially, "onto" and "from" give us a grab-bag of supports.  We combine them together.

  // We can also have conflicting supports.  Let's describe in text what'll combine and what'll conflict.

  /*
     For a given supportee, we try to pair up identical supporters.  If we can't pair them up one-to-one, what happens:

       - we replace the PointerFrom's with LostTrack
       - the FieldOf's and DescopingElements had damn well better match up, and they're retained (in fact, there must be <= 1 of them in total)
       - we return Fresh (not Stale)

     TODO(): Obviously we'd like to avoid LostTrack and handle things better.
  */

  initial_pairage vs_unify_pairage = {
    {false, None, mk_array(), false},
    {false, None, mk_array(), false}
  };

  bu hash[cell_num, vs_unify_pairage];

  foreach supp *vs_support in refs(&onto->supports) {
    ign bool = try_insert_ref(&bu, &supp->supportee, &initial_pairage);
    pa *vs_unify_pairage = unHas!lookup_ref(&bu, &supp->supportee);
    #add_supp(&pa->for_onto, supp);
  }

  foreach supp *vs_support in refs(&from->supports) {
    ign bool = try_insert_ref(&bu, &supp->supportee, &initial_pairage);
    pa *vs_unify_pairage = unHas!lookup_ref(&bu, &supp->supportee);
    #add_supp(&pa->for_from, supp);
  }

  new_supports array[vs_support];

  fresh bool = false;

  it hash_iter[cell_num, vs_unify_pairage] = iter(&bu);
  while case Has(p *tup[_, _]) = next(&it) {
    supportee cell_num = p->car;
    oh *vs_unify_half_pairage = &p->cdr.for_onto;
    fh *vs_unify_half_pairage = &p->cdr.for_from;
    if oh->descoping != fh->descoping {
      return ERR(_u8("Inconsistent descoping state for "), supportee);
    }
    if oh->fieldof != fh->fieldof {
      return ERR(_u8("Inconsistent fieldof state for "), supportee);
    }
    if oh->descoping && isHas(&oh->fieldof) {
      return ERR(_u8("Field has descoping element for field "), supportee);
    }
    if oh->descoping {
      push(&new_supports, {DescopingElement(supportee), supportee});
    }
    if case Has(d cell_num) = oh->fieldof {
      push(&new_supports, {FieldOf(d), supportee});
    }
    losttrack bool = oh->losttrack | fh->losttrack;
    if !losttrack {
      if count(&oh->inpointers) != count(&fh->inpointers) {
        DBG_losttrack(_u8("unify count mismatch loses track"));
        losttrack = true;
        fresh = true;
      } else {
        // Right now it's p easy to see if inpointers pair up.
        sort(&oh->inpointers);
        sort(&fh->inpointers);
        if !array_equal(&oh->inpointers, &fh->inpointers) {
          DBG_losttrack(_u8("unify array inequality loses track"));
          losttrack = true;
          fresh = true;
        }
      }
    }

    if losttrack {
      DBG_losttrack(_u8("LostTrack"));
      push(&new_supports, {LostTrack, supportee});
    } else {
      foreach inpointer cell_num in elems(&oh->inpointers) {
        push(&new_supports, {PointerFrom(inpointer), supportee});
      }
    }
  }

  swap(&onto->supports, &new_supports);

  return NoFail(fresh then @[freshness]Fresh else @[freshness]Stale);
}

func add_supp(hp *vs_unify_half_pairage, supp *vs_support) np {
  switch &supp->supporter {
  case &PointerFrom(c cell_num):
    push(&hp->inpointers, c);
  case &FieldOf(c cell_num):
    if case Has(d cell_num) = hp->fieldof {
      if d == c {
        return ERR(_u8("ICE?  FieldOf already present, cells match."));
      } else {
        return ERR(_u8("ICE?  FieldOf already present, cells do NOT match."));
      }
    } else {
      hp->fieldof = Has(c);
    }
  case &DescopingElement(c cell_num):
    if c != supp->supportee {
      return ERR(_u8("ICE?  Mismatched descoping elem"));
    }
    if hp->descoping {
      return ERR(_u8("ICE?  Multiple descoping elems for cell "), c);
    }
    hp->descoping = true;
  case &LostTrack:
    hp->losttrack = true;
  }
  return NoFail;
}

func vs_xop(c cgt, gn gr_num, xn *gr_xnode) np {
  xn->vs_xopped = true;
  vs *vt_state = &c.track->current;

  vs_checksum_xop(&vs->checksum, &xn->op);

  #vs_support_xop(vs, &xn->op);

  return NoFail;
}

func vs_support_xop(vs *vt_state, op *gr_xop) np {
  switch op {
  case &GrApply(a gr_apply): {
    // We don't know what we're doing yet so we just call these do-nothing functions.
    #vs_support_deactivate(vs, a.funcell);
    #vs_support_descope(vs, a.funcell);
    foreach c cell_num in elems(&a.params) {
      // This is the opposite of typical destruction order.  But it shouldn't matter because we don't really know the order, do we?
      #vs_support_deactivate(vs, c);
      #vs_support_descope(vs, c);
    }

    #vs_support_activate(vs, a.retcell);

    switch a.semantic {
    case NoSemantic: { }
    case MoveSemantic(bs gr_apply_bi_semantic):
      #vs_support_copy_properties(vs, bs.dest, bs.src);
      #vs_support_activate(vs, bs.dest);
      #vs_support_deactivate(vs, bs.src);
    case CopySemantic(bs gr_apply_bi_semantic):
      #vs_support_copy_properties(vs, bs.dest, bs.src);
      #vs_support_activate(vs, bs.dest);
    case InitSemantic(us gr_apply_uni_semantic):
      #vs_support_activate(vs, us.cell);
    case DestroySemantic(us gr_apply_uni_semantic):
      #vs_support_deactivate(vs, us.cell);
    }
    return NoFail;
  }
  case &GrPrimApply(a gr_prim_apply): {
    foreach c cell_num in elems(&a.params) {
      #vs_support_descope(vs, c);
    }
    #vs_support_activate(vs, a.retcell);
    return NoFail;
  }
  case &GrMemCopy(a gr_memcopy):
    #vs_support_copy_properties(vs, a.dest, a.src);
    return NoFail;
  case &GrWriteConst(a gr_writeconst):
    #vs_support_const_properties(vs, a.dest);
    return NoFail;
  case &GrAddressof(a gr_addressof):
    #vs_support_activate(vs, a.dest);
    #vs_support_add(vs, {PointerFrom(a.dest), a.addressee});
    return NoFail;
  case &GrDeref(a gr_deref):
    #vs_support_add(vs, {PointerFrom(a.pointer), a.name});
    return NoFail;
  case &GrSubcell(a gr_subcell):
    #vs_support_add(vs, {FieldOf(a.partof), a.name});
    return NoFail;
  case &GrLive(a gr_live):
    #vs_support_enscope(vs, a.cell);
    return NoFail;
  case &GrAssertLive(a gr_assert_live):
    return NoFail;
  case &GrDead(a gr_dead):
    #vs_support_descope(vs, a.cell);
    return NoFail;
  case &GrVirtualDead(a gr_virtual_dead):
    #vs_support_virtualdead(vs, a.cell);
    return NoFail;
  case &GrActiveXop(a gr_active_xop):
    #vs_support_active_op(vs, a.op1);
    #vs_support_active_op(vs, a.op2);
    return NoFail;
  case &GrManyActiveXop(a gr_many_active_xop):
    foreach aop gr_active_op in elems(&a.ops) {
      #vs_support_active_op(vs, aop);
    }
    return NoFail;
  }
}

// TODO(): Generally speaking, make this be non-broken.

func vs_support_add(vs *vt_state, supp vs_support) np {
  push(&vs->supports, supp);
  return NoFail;
}

func vs_support_enscope(vs *vt_state, c cell_num) np {
  #vs_support_add(vs, {DescopingElement(c), c});
  return NoFail;
}

// Cases where c is the _supporter_ should have been handled if/when the cell got deactivated.
inline func vs_descope_removes_support(supp *vs_support, c cell_num) bool {
  return supp->supportee == c;
}

func vs_support_descope(vs *vt_state, c cell_num) np {
  // If we descope, that means... we become deceased
  // TODO(): a way to deactivate anything that referenced us

  n size = count(&vs->supports);
  w size = 0;
  for i size = 0; i < n; i++ {
    supp *vs_support = &vs->supports[i];
    if !vs_descope_removes_support(supp, c) {
      vs->supports[w] = *supp;
      w++;
    }
  }
  truncate(&vs->supports, w);
  return NoFail;
}

func vs_support_activate(vs *vt_state, c cell_num) np {
  // I think this means nothing.
  return NoFail;
}

// Cases where c is the _supportee_ would be handled at descoping(?)
func vs_deactivate_removes_support(supp *vs_support, c cell_num) bool {
  switch &supp->supporter {
  case &PointerFrom(d cell_num):
    return d == c;
  case &FieldOf(d cell_num):
    return false;
  case &DescopingElement(d cell_num):
    return false;
  case &LostTrack(v void):
    return false;
  }
}

func vs_support_deactivate(vs *vt_state, c cell_num) np {
  // vs_support_const_properties calls this, check if that makes sense if you modify this.
  n size = count(&vs->supports);
  w size = 0;
  for i size = 0; i < n; i++ {
    supp *vs_support = &vs->supports[i];
    if !vs_deactivate_removes_support(supp, c) {
      vs->supports[w] = *supp;
      w++;
    }
  }
  truncate(&vs->supports, w);

  return NoFail;
}

func vs_support_copy_properties(vs *vt_state, dest cell_num, src cell_num) np {
  // Okay, what properties are copied?
  // In general, I think, emitted support, but _not_ (necessarily) exposed information.

  n size = count(&vs->supports);
  for i size = 0; i < n; i++ {
    supp *vs_support = &vs->supports[i];
    switch &supp->supporter {
    case &PointerFrom(d cell_num):
      if d == src {
        #vs_support_add(vs, {PointerFrom(dest), supp->supportee});
      }
    case &FieldOf(d cell_num): {
      // For what it's worth, the support from a field to its struct owner is _not_ emitted support.  So it's not an exception that it doesn't get copied.
    }
    case &DescopingElement(d cell_num): { }
    case &LostTrack(v void): { }
    }
    // supp is inv
  }

  return NoFail;
}

func vs_support_const_properties(vs *vt_state, dest cell_num) np {
  // We'll probably need the const value, too...
  // If we're overwriting a pointer... it's essentially deactivation for now.
  return vs_support_deactivate(vs, dest);
}

func vs_support_virtualdead(vs *vt_state, c cell_num) np {
  n size = count(&vs->supports);
  w size = 0;
  for i size = 0; i < n; i++ {
    supp *vs_support = &vs->supports[i];
    incr_w size;
    if supp->supportee == c {
      // We drop this.
      incr_w = 0;
    } else {
      switch &supp->supporter {
      case &PointerFrom(d cell_num):
        if d == c {
          DBG_losttrack(_u8("VirtualDead pointer LostTrack"));
          // Uh yeah we update in-place.
          // This could also be improved.
          supp->supporter = LostTrack;
        }
        incr_w = 1;
      case &FieldOf(d cell_num):
        // How should this work?  We really do lose track of support, but... obviously this could be improved.
        if d == c {
          // DBG_losttrack(_u8("VirtualDead field LostTrack"));
          supp->supporter = LostTrack;
        }
        incr_w = 1;
      case &DescopingElement(d cell_num):
        // We shouldn't have any descoping elements for virtual cells.
        check(d != c);
        incr_w = 1;
      case &LostTrack:
        incr_w = 1;
      }
    }
    vs->supports[w] = vs->supports[i];
    w += incr_w;
  }
  truncate(&vs->supports, w);

  return NoFail;
}

func vs_support_active_op(vs *vt_state, op gr_active_op) np {
  switch op {
  case Nothing: { }
  case Activate(c cell_num):
    #vs_support_activate(vs, c);
  case Deactivate(c cell_num):
    #vs_support_deactivate(vs, c);
  }
  return NoFail;
}


func vs_checksum_xop(vs *vs_checksum, op *gr_xop) void {
  switch op {
  case &GrApply(a gr_apply):
    switch a.act {
    case TwoExtraOps(ops gr_active_xop):
      vs_checksum_active_op(vs, ops.op1);
      vs_checksum_active_op(vs, ops.op2);
    case StandardApply: { }
    }
    nparams i32 = ~count(&a.params);
    // funcell deactivates, params deactivate, return cell activates
    vs->active_count += -nparams;
    // funcell dead, params dead, return cell was already live
    vs->live_count += -nparams - 1;
  case &GrPrimApply(a gr_prim_apply):
    nparams i32 = ~count(&a.params);
    // Same as GrApply except without the funcell.
    vs->active_count += -nparams + 1;
    vs->live_count += -nparams;
  case &GrMemCopy(a gr_memcopy): { }
  case &GrWriteConst(a gr_writeconst): { }
  case &GrAddressof(a gr_addressof):
    vs->active_count++;
  case &GrDeref(a gr_deref):
    vs->live_count++;
  case &GrSubcell(a gr_subcell):
    vs->live_count++;
  case &GrLive(a gr_live):
    vs->live_count++;
  case &GrAssertLive(a gr_assert_live): { }
  case &GrDead(a gr_dead):
    vs->live_count--;
  case &GrVirtualDead(a gr_virtual_dead):
    vs->live_count--;
  case &GrActiveXop(a gr_active_xop):
    vs_checksum_active_op(vs, a.op1);
    vs_checksum_active_op(vs, a.op2);
  case &GrManyActiveXop(a gr_many_active_xop):
    foreach aop gr_active_op in elems(&a.ops) {
      vs_checksum_active_op(vs, aop);
    }
  }
}

func vs_checksum_active_op(vs *vs_checksum, op gr_active_op) void {
  switch op {
  case Nothing: { }
  case Activate(c cell_num):
    vs->active_count++;
  case Deactivate(c cell_num):
    vs->active_count--;
  }
}

// TODO: Get rid of this entirely, for performance.
func[T] DBG_losttrack(x T) void {
  // DBG(x);
}
