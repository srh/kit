import graph;
import valstate;

struct vt_track {
  current vt_state;

  // Indexed by gr_num.
  annot array[vt_annot];
}

struct vt_freshtrack {
  fresh array[sq_num];
  end_state opt[vt_state];
}

func mk_track(gr *frame_graph) vt_track {
  return {
    mk_vt_state(),
    repeat(count(&gr->ops), {None, Stale})
  };
}

struct vt_annot {
  savestate opt[vt_state];
  // If it's fresh, savestate had darn well better not be None.
  fr freshness;
}

struct cgt {
  clq *clqueue;
  gr *frame_graph;
  track *vt_track;
}

func ensure_def_inst_valtracked(clq *clqueue, ent_id def_entry_id, inst_id def_inst_id) np {
  #ensure_def_inst_graphed(clq, ent_id, inst_id);
  #vt_regraphed(clq, un(&ref_inst(clq->cs, inst_id)->graph));
  return NoFail;
}

func vt_regraphed(clq *clqueue, fg *frame_regraphed) np {
  return vt_graph(clq, &fg->gr, fg->sn);
}

func vt_graph(clq *clqueue, gr *frame_graph, sn sq_num) np {
  // DBG(_u8!"valtracking for graph ", lookup(clq->im, gr->informal_name));
  /* This uses a different traversal algorithm than some other graph-traversing code.
  Metadata that tells us about the AST's structure make us revisit alternate branches more
  "locally," and more importantly, in a defined order that can be described in terms of
  the original AST. */
  /* TODO: Make the above comment be true.  Right now we don't really have a defined order. */

  track vt_track = mk_track(gr);

  #vt_inner_expr({clq, gr, &track}, sn);
  return NoFail;
}

// Returns true if the inner_expr can terminate (in which case c.track->current means something).
func vt_inner_expr(c cgt, outer_sn sq_num) np {
  ft vt_freshtrack = {mk_array@[sq_num](), None};
  fr freshness = #vt_unify(c, &ft, outer_sn);
  while case Has(sn sq_num) = popval(&ft.fresh) {
    if c.track->annot[sn.x.x].fr == Fresh {
      c.track->current = *unHas(&c.track->annot[sn.x.x].savestate);
      #vt_xops(c, &ft, sn);
    }
  }
  if case &Has(st vt_state) = &ft.end_state {
    c.track->current = st;
    return NoFail;
  } else {
    return NoFail;
  }
}

func vt_xops(c cgt, ft *vt_freshtrack, sn sq_num) np {
  for ;; {
    qn *gr_qnode = ref_qnode(c.gr, sn);
    if qn->indegree.x > 1 {
      if Stale == #vt_unify(c, ft, sn) {
        return NoFail;
      }
    }
    c.track->annot[sn.x.x].fr = Stale;
    switch &qn->op {
    case &GrBranch(a gr_branch):
      ntargets size = branch_target_count(&a);
      for i size = 0; i < ntargets; i++ {
        target *gr_branch_target = branch_target_ref(&a, i);
        switch target->disposition {
        case ForwardTarget:
          #vt_track_soon(c, ft, target->sn);
        case LoopingTarget:
          #vt_track_soon(c, ft, target->sn);
        case AbnormalTarget:
          saved_state vt_state = c.track->current;
          #vt_abnormal_excursion(c, ft, target->sn);
          c.track->current = saved_state;
        }
      }
      return NoFail;
    case &GrSequence(a gr_sequence):
      #vt_single_xop(c, a.first);
      sn = a.second;
      // loop around
    case &GrJmp(a gr_jmp):
      switch a.disposition {
      case JmpForward:
        sn = a.next;
      case ExitNormalcy(b gr_jmp_exit_normalcy):
        #vt_abnormal_excursion(c, ft, a.next);
        return NoFail;
      case ReenterNormalcy:
        ice(_u8("vt_xops sees GrJmp ReenterNormalcy"));
      }
    case &GrQNop:
      fr freshness = #unify_vt_state(&ft->end_state, &c.track->current);
      return NoFail;
    }
  }
}

func vt_abnormal_excursion(c cgt, ft *vt_freshtrack, sn sq_num) np {
  for ;; {
    qn *gr_qnode = ref_qnode(c.gr, sn);
    // Abnormal excursions could merge together, yes.
    if qn->indegree.x > 1 {
      if Stale == #vt_unify(c, ft, sn) {
        return NoFail;
      }
    }
    c.track->annot[sn.x.x].fr = Stale;
    switch &qn->op {
    case &GrBranch(a gr_branch):
      ice(_u8("vt_abnormal_excursion sees a branch"));
    case &GrSequence(a gr_sequence):
      #vt_single_xop(c, a.first);
      sn = a.second;
    case &GrJmp(a gr_jmp):
      switch a.disposition {
      case JmpForward:
        sn = a.next;
      case ExitNormalcy(b gr_jmp_exit_normalcy):
        ice(_u8("vt_abnormal_excursion sees an ExitNormalcy"));
      case ReenterNormalcy:
        fr freshness = #vt_unify(c, ft, a.next);
        return NoFail;
      }
    case &GrQNop:
      ice(_u8("vt_abnormal_excursion sees a QNop (is it final_node?)"));
    }
  }
}

// Returns true if we reached the end of the single xop.  If true, c.track->current means
// something.  If false, it doesn't!
func vt_single_xop(c cgt, gn gr_num) np {
  switch ref_node(c.gr, gn) {
  case &XOp(xn gr_xnode):
    return vs_xop(c, gn, &xn);
  case &QOp(qn gr_qnode):
    crash(_u8("vt_single_xop sees a sub-qop-expr"));
    return fake();
  }
}

func vt_unify(c cgt, ft *vt_freshtrack, sn sq_num) cr[freshness] {
  old_fr freshness = c.track->annot[sn.x.x].fr;
  fr freshness = #unify_vt_state(&c.track->annot[sn.x.x].savestate, &c.track->current);
  switch old_fr {
  case Fresh:
    return NoFail(Fresh);
  case Stale:
    switch fr {
    case Fresh:
      c.track->annot[sn.x.x].fr = Fresh;
      push(&ft->fresh, sn);
      return NoFail(Fresh);
    case Stale:
      return NoFail(Stale);
    }
  }
}

func vt_track_soon(c cgt, ft *vt_freshtrack, sn sq_num) np {
  fr freshness = #vt_unify(c, ft, sn);
  return NoFail;
}
